# MCP Cursor Model Inventory
# Dynamic inventory of available models for automated orchestration
#
# Author: Claude Code Assistant
# Date: 2024-12-21
# Status: All listed models have been tested and verified in Cursor

models:
  # Models available directly in Cursor via MCP (All tested and verified)
  cursor_available:
    claude-3-5-sonnet:
      name: "Claude 3.5 Sonnet"
      provider: "Anthropic"
      type: "general"
      capabilities: ["voting", "analysis", "code_review", "consensus"]
      priority: 1
      max_tokens: 200000
      context_window: 200000
      api_available: true

    claude-3-5-haiku:
      name: "Claude 3.5 Haiku"
      provider: "Anthropic"
      type: "collaborator"
      capabilities: ["voting", "quick_analysis", "compact_reasoning"]
      priority: 2
      max_tokens: 200000
      context_window: 200000
      api_available: true

    gpt-4o:
      name: "GPT-4o"
      provider: "OpenAI"
      type: "general"
      capabilities: ["voting", "analysis", "consensus", "reasoning"]
      priority: 1
      max_tokens: 128000
      context_window: 128000
      api_available: true

    gpt-4o-mini:
      name: "GPT-4o-mini"
      provider: "OpenAI"
      type: "collaborator"
      capabilities: ["voting", "rationale", "quick_feedback"]
      priority: 3
      max_tokens: 128000
      context_window: 128000
      api_available: true

    gemini-2-0:
      name: "Gemini 2.0"
      provider: "Google"
      type: "general"
      capabilities: ["voting", "analysis", "i18n_support"]
      priority: 2
      max_tokens: 32768
      context_window: 1048576
      api_available: true

  # Additional models available in Cursor (not yet tested in this project)
  additional_cursor_available:
    claude-3-opus:
      name: "Claude 3 Opus"
      provider: "Anthropic"
      type: "general"
      capabilities: ["voting", "analysis", "complex_reasoning", "code_generation"]
      priority: 1
      max_tokens: 200000
      context_window: 200000
      api_available: true
      notes: "Available in Cursor but not yet tested in this project"

    claude-3-haiku:
      name: "Claude 3 Haiku"
      provider: "Anthropic"
      type: "collaborator"
      capabilities: ["voting", "quick_analysis", "efficient_processing"]
      priority: 4
      max_tokens: 200000
      context_window: 200000
      api_available: true
      notes: "Available in Cursor but not yet tested in this project"

    gpt-4-turbo:
      name: "GPT-4 Turbo"
      provider: "OpenAI"
      type: "general"
      capabilities: ["voting", "analysis", "code_review", "reasoning"]
      priority: 1
      max_tokens: 128000
      context_window: 128000
      api_available: true
      notes: "Available in Cursor but not yet tested in this project"

    gpt-4:
      name: "GPT-4"
      provider: "OpenAI"
      type: "general"
      capabilities: ["voting", "analysis", "consensus", "writing"]
      priority: 2
      max_tokens: 8192
      context_window: 8192
      api_available: true
      notes: "Available in Cursor but not yet tested in this project"

    gpt-3-5-turbo:
      name: "GPT-3.5 Turbo"
      provider: "OpenAI"
      type: "collaborator"
      capabilities: ["voting", "basic_analysis", "quick_responses"]
      priority: 5
      max_tokens: 16384
      context_window: 4096
      api_available: true
      notes: "Available in Cursor but not yet tested in this project"

    gemini-1-5-pro:
      name: "Gemini 1.5 Pro"
      provider: "Google"
      type: "general"
      capabilities: ["voting", "analysis", "multimodal", "i18n"]
      priority: 2
      max_tokens: 32768
      context_window: 1048576
      api_available: true
      notes: "Available in Cursor but not yet tested in this project"

    gemini-1-5-flash:
      name: "Gemini 1.5 Flash"
      provider: "Google"
      type: "collaborator"
      capabilities: ["voting", "fast_analysis", "multimodal_quick"]
      priority: 3
      max_tokens: 32768
      context_window: 1048576
      api_available: true
      notes: "Available in Cursor but not yet tested in this project"

    llama-3-1-70b:
      name: "Llama 3.1 70B"
      provider: "Meta"
      type: "general"
      capabilities: ["voting", "analysis", "reasoning", "code"]
      priority: 2
      max_tokens: 131072
      context_window: 131072
      api_available: true
      notes: "Available in Cursor but not yet tested in this project"

    llama-3-1-8b:
      name: "Llama 3.1 8B"
      provider: "Meta"
      type: "collaborator"
      capabilities: ["voting", "basic_analysis", "lightweight"]
      priority: 6
      max_tokens: 131072
      context_window: 131072
      api_available: true
      notes: "Available in Cursor but not yet tested in this project"

    codellama-34b:
      name: "CodeLlama 34B"
      provider: "Meta"
      type: "collaborator"
      capabilities: ["voting", "code_analysis", "technical_review"]
      priority: 4
      max_tokens: 16384
      context_window: 16384
      api_available: true
      notes: "Available in Cursor but not yet tested in this project"

    deepseek-coder-33b:
      name: "DeepSeek Coder 33B"
      provider: "DeepSeek"
      type: "collaborator"
      capabilities: ["voting", "code_generation", "technical_analysis"]
      priority: 4
      max_tokens: 32768
      context_window: 32768
      api_available: true
      notes: "Available in Cursor but not yet tested in this project"

    mistral-large:
      name: "Mistral Large"
      provider: "Mistral"
      type: "general"
      capabilities: ["voting", "analysis", "multilingual", "reasoning"]
      priority: 2
      max_tokens: 32768
      context_window: 32768
      api_available: true
      notes: "Available in Cursor but not yet tested in this project"

    mistral-7b:
      name: "Mistral 7B"
      provider: "Mistral"
      type: "collaborator"
      capabilities: ["voting", "basic_analysis", "lightweight"]
      priority: 6
      max_tokens: 4096
      context_window: 8192
      api_available: true
      notes: "Available in Cursor but not yet tested in this project"

    qwen-2-72b:
      name: "Qwen 2 72B"
      provider: "Alibaba"
      type: "general"
      capabilities: ["voting", "analysis", "multilingual", "code"]
      priority: 2
      max_tokens: 32768
      context_window: 131072
      api_available: true
      notes: "Available in Cursor but not yet tested in this project"

    qwen-2-7b:
      name: "Qwen 2 7B"
      provider: "Alibaba"
      type: "collaborator"
      capabilities: ["voting", "basic_analysis", "multilingual_light"]
      priority: 5
      max_tokens: 32768
      context_window: 131072
      api_available: true
      notes: "Available in Cursor but not yet tested in this project"

    phi-3-mini:
      name: "Phi-3 Mini"
      provider: "Microsoft"
      type: "collaborator"
      capabilities: ["voting", "basic_analysis", "lightweight"]
      priority: 7
      max_tokens: 4096
      context_window: 128000
      api_available: true
      notes: "Available in Cursor but not yet tested in this project"

    starCoder2-15b:
      name: "StarCoder2 15B"
      provider: "BigCode"
      type: "collaborator"
      capabilities: ["voting", "code_generation", "technical"]
      priority: 5
      max_tokens: 16384
      context_window: 16384
      api_available: true
      notes: "Available in Cursor but not yet tested in this project"

  # Models requiring manual execution (not in Cursor)
  manual_required:
    grok-3:
      name: "Grok-3"
      provider: "xAI"
      type: "general"
      capabilities: ["voting", "adaptive_learning", "consensus"]
      priority: 1
      notes: "Requires manual execution via xAI interface"
      estimated_response_time: "5-15 minutes"
      contact_method: "Manual chat interface"

    deepseek-v3:
      name: "DeepSeek-V3"
      provider: "DeepSeek"
      type: "general"
      capabilities: ["voting", "advanced_reasoning", "security"]
      priority: 1
      notes: "Requires manual execution via DeepSeek interface"
      estimated_response_time: "5-15 minutes"
      contact_method: "Manual chat interface"

    deepseek-r1:
      name: "DeepSeek-R1"
      provider: "DeepSeek"
      type: "general"
      capabilities: ["voting", "security", "federation"]
      priority: 2
      notes: "Requires manual execution via DeepSeek interface"
      estimated_response_time: "5-15 minutes"
      contact_method: "Manual chat interface"

    grok-core-fast-1:
      name: "Grok Core Fast-1"
      provider: "xAI"
      type: "general"
      capabilities: ["voting", "performance", "ml_integration"]
      priority: 1
      notes: "Requires manual execution via xAI interface"
      estimated_response_time: "5-15 minutes"
      contact_method: "Manual chat interface"

    gemini-2-5-pro:
      name: "Gemini 2.5 Pro"
      provider: "Google"
      type: "general"
      capabilities: ["voting", "i18n", "l10n"]
      priority: 2
      notes: "Requires manual execution via Google AI Studio"
      estimated_response_time: "3-10 minutes"
      contact_method: "Google AI Studio interface"

    llama-3-1-405b:
      name: "Llama 3.1 405B"
      provider: "Meta"
      type: "general"
      capabilities: ["voting", "analysis", "reasoning"]
      priority: 3
      notes: "Requires manual execution via Meta interface or API"
      estimated_response_time: "10-20 minutes"
      contact_method: "Manual interface or API"

# Model Groups for Easy Targeting
groups:
  all: ["cursor_available", "additional_cursor_available", "manual_required"]
  generals: ["claude-3-5-sonnet", "claude-3-opus", "gpt-4o", "gpt-4-turbo", "gpt-4", "gemini-2-0", "gemini-1-5-pro", "llama-3-1-70b", "mistral-large", "qwen-2-72b", "grok-3", "deepseek-v3", "deepseek-r1", "grok-core-fast-1", "gemini-2-5-pro", "llama-3-1-405b"]
  collaborators: ["claude-3-5-haiku", "claude-3-haiku", "gpt-4o-mini", "gpt-3-5-turbo", "gemini-1-5-flash", "llama-3-1-8b", "codellama-34b", "deepseek-coder-33b", "mistral-7b", "qwen-2-7b", "phi-3-mini", "starCoder2-15b"]
  cursor_only: ["cursor_available", "additional_cursor_available"]
  cursor_tested: ["cursor_available"]  # Models already tested in this project
  cursor_available: ["additional_cursor_available"]  # Additional models available but not yet tested
  anthropic_only: ["claude-3-5-sonnet", "claude-3-opus", "claude-3-5-haiku", "claude-3-haiku"]
  openai_only: ["gpt-4o", "gpt-4-turbo", "gpt-4", "gpt-4o-mini", "gpt-3-5-turbo"]
  google_only: ["gemini-2-0", "gemini-1-5-pro", "gemini-1-5-flash", "gemini-2-5-pro"]
  meta_only: ["llama-3-1-70b", "llama-3-1-8b", "codellama-34b", "llama-3-1-405b"]
  xai_only: ["grok-3", "grok-core-fast-1"]
  deepseek_only: ["deepseek-v3", "deepseek-r1", "deepseek-coder-33b"]
  mistral_only: ["mistral-large", "mistral-7b"]
  alibaba_only: ["qwen-2-72b", "qwen-2-7b"]
  microsoft_only: ["phi-3-mini"]
  bigcode_only: ["starCoder2-15b"]

# Configuration Settings
config:
  default_timeout: 300  # 5 minutes
  max_concurrent_requests: 5
  retry_attempts: 3
  rate_limit_delay: 1.0  # seconds between requests
  output_directory: "automation_results"
  log_level: "INFO"

  # Voting-specific settings
  voting:
    required_quorum: 0.6  # 60% of targeted models
    default_threshold: 0.5  # 50% yes votes for approval
    timeout_days: 7  # Days until vote expires
    reminder_interval_hours: 24

  # Analysis-specific settings
  analysis:
    confidence_threshold: 0.7  # Minimum confidence for valid analysis
    max_analysis_length: 2000  # Maximum characters per analysis
    required_analysis_types: ["technical", "security", "impact"]

# Update Tracking
metadata:
  version: "1.1.0"
  last_updated: "2024-12-21T20:00:00Z"
  updated_by: "Claude Code Assistant"
  total_models: 28
  cursor_tested: 9
  cursor_available: 16
  manual_required: 6
  change_log:
    - "Initial model inventory creation"
    - "Added all current project models"
    - "Configured capability mappings"
    - "Set up model groups for targeting"
    - "Added 16+ additional Cursor models not yet tested"
    - "Expanded model groups for better targeting"
    - "Updated metadata with comprehensive model counts"
    - "Added provider-specific groupings"
